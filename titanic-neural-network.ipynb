{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "9e319230-1cc2-4b19-ad66-06a07e07fc60",
    "_execution_state": "idle",
    "_uuid": "03de849fb872e11b3db2a2c99563783ce6ba784f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/pi/anaconda3/envs/nitp-hack/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pi/anaconda3/envs/nitp-hack/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pi/anaconda3/envs/nitp-hack/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pi/anaconda3/envs/nitp-hack/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pi/anaconda3/envs/nitp-hack/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pi/anaconda3/envs/nitp-hack/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Import all the libraries I need\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# ignore Deprecation Warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import keras \n",
    "from keras.models import Sequential # intitialize the ANN\n",
    "from keras.layers import Dense      # create layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 12),\n",
       " (418, 11),\n",
       " array(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "        'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'], dtype=object))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# load the data\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df = df_train.append(df_test , ignore_index = True)\n",
    "\n",
    "# some quick inspections\n",
    "df_train.shape, df_test.shape, df_train.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0999117e-8f23-4f1f-ad3c-44c673b68c01",
    "_execution_state": "idle",
    "_uuid": "377bf53e885fb8a4e49d1cdc07bed9951c053da2"
   },
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pi/anaconda3/envs/nitp-hack/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/home/pi/anaconda3/envs/nitp-hack/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df['Title'] = df['Name'].map( lambda x: x.split(',')[1].split( '.' )[0].strip())\n",
    "\n",
    "df['Title'] = df['Title'].replace('Mlle', 'Miss')\n",
    "df['Title'] = df['Title'].replace(['Mme','Lady','Ms'], 'Mrs')\n",
    "df.Title.loc[ (df.Title !=  'Master') & (df.Title !=  'Mr') & (df.Title !=  'Miss') \n",
    "             & (df.Title !=  'Mrs')] = 'Others'\n",
    "\n",
    "\n",
    "df = pd.concat([df, pd.get_dummies(df['Title'])], axis=1).drop(labels=['Name'], axis=1)\n",
    "\n",
    "# map the two genders to 0 and 1\n",
    "df.Sex = df.Sex.map({'male':0, 'female':1})\n",
    "\n",
    "# create a new feature \"Family\"\n",
    "df['Family'] = df['SibSp'] + df['Parch'] + 1\n",
    "\n",
    "df.Family = df.Family.map(lambda x: 0 if x > 4 else x)\n",
    "\n",
    "df.Ticket = df.Ticket.map(lambda x: x[0])\n",
    "\n",
    "guess_Fare = df.Fare.loc[ (df.Ticket == '3') & (df.Pclass == 3) & (df.Embarked == 'S')].median()\n",
    "df.Fare.fillna(guess_Fare , inplace=True)\n",
    "\n",
    "# inspect the mean Fare values for people who died and survived\n",
    "df[['Fare', 'Survived']].groupby(['Survived'],as_index=False).mean()\n",
    "\n",
    "# bin Fare into five intervals with equal amount of people\n",
    "df['Fare-bin'] = pd.qcut(df.Fare,5,labels=[1,2,3,4,5]).astype(int)\n",
    "\n",
    "\n",
    "# notice that instead of using Title, we should use its corresponding dummy variables \n",
    "df_sub = df[['Age','Master','Miss','Mr','Mrs','Others','Fare-bin','SibSp']]\n",
    "\n",
    "X_train  = df_sub.dropna().drop('Age', axis=1)\n",
    "y_train  = df['Age'].dropna()\n",
    "X_test = df_sub.loc[np.isnan(df.Age)].drop('Age', axis=1)\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators = 300)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = np.round(regressor.predict(X_test),1)\n",
    "df.Age.loc[df.Age.isnull()] = y_pred\n",
    "\n",
    "bins = [ 0, 4, 12, 18, 30, 50, 65, 100] # This is somewhat arbitrary...\n",
    "age_index = (1,2,3,4,5,6,7)\n",
    "#('baby','child','teenager','young','mid-age','over-50','senior')\n",
    "df['Age-bin'] = pd.cut(df.Age, bins, labels=age_index).astype(int)\n",
    "\n",
    "df['Ticket'] = df['Ticket'].replace(['A','W','F','L','5','6','7','8','9'], '4')\n",
    "\n",
    "df = df.drop(labels=['Cabin'], axis=1)\n",
    "\n",
    "# fill the NAN\n",
    "df.Embarked.fillna('S' , inplace=True )\n",
    "\n",
    "df = df.drop(labels='Embarked', axis=1)\n",
    "\n",
    "# dummy encoding\n",
    "df = pd.get_dummies(df,columns=['Ticket'])\n",
    "\n",
    "df = df.drop(labels=['SibSp','Parch','Age','Fare','Title','PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "_cell_guid": "bb1fc2fe-1947-4f89-99fa-d621711615fc",
    "_execution_state": "idle",
    "_uuid": "93e6890cecf2d3ae919ec30b24588d780092720d"
   },
   "outputs": [],
   "source": [
    "def preprocessing(dfInput):\n",
    "    df = dfInput.copy()\n",
    "    df['Title'] = df.Name.map(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "\n",
    "    df['Title'] = df['Title'].replace('Mlle', 'Miss')\n",
    "    df['Title'] = df['Title'].replace(['Mme', 'Lady', 'Ms'], 'Mrs')\n",
    "    df.Title.loc[(df.Title != 'Master') & (df.Title != 'Mr') & (df.Title != 'Miss')\n",
    "                 & (df.Title != 'Mrs')] = 'Others'\n",
    "    df = pd.concat([df, pd.get_dummies(df['Title'])],\n",
    "                   axis=1).drop(labels=['Name'], axis=1)\n",
    "\n",
    "    # map the two genders to 0 and 1\n",
    "    df.Sex = df.Sex.map({'male': 0, 'female': 1})\n",
    "\n",
    "    # create a new feature \"Family\"\n",
    "    df['Family'] = df['SibSp'] + df['Parch'] + 1\n",
    "\n",
    "    df.Family = df.Family.map(lambda x: 0 if x > 4 else x)\n",
    "\n",
    "    df.Ticket = df.Ticket.map(lambda x: x[0])\n",
    "\n",
    "    guess_Fare = df.Fare.loc[(df.Ticket == '3') & (\n",
    "        df.Pclass == 3) & (df.Embarked == 'S')].median()\n",
    "    df.Fare.fillna(guess_Fare, inplace=True)\n",
    "\n",
    "    # inspect the mean Fare values for people who died and survived\n",
    "    df[['Fare', 'Survived']].groupby(['Survived'], as_index=False).mean()\n",
    "\n",
    "    # bin Fare into five intervals with equal amount of people\n",
    "    df['Fare-bin'] = pd.qcut(df.Fare, 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "\n",
    "    # notice that instead of using Title, we should use its corresponding dummy variables\n",
    "    df_sub = df[['Age', 'Master', 'Miss', 'Mr',\n",
    "                 'Mrs', 'Others', 'Fare-bin', 'SibSp']]\n",
    "\n",
    "    X_train = df_sub.dropna().drop('Age', axis=1)\n",
    "    y_train = df['Age'].dropna()\n",
    "    X_test = df_sub.loc[np.isnan(df.Age)].drop('Age', axis=1)\n",
    "\n",
    "    regressor = RandomForestRegressor(n_estimators=300)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = np.round(regressor.predict(X_test), 1)\n",
    "    df.Age.loc[df.Age.isnull()] = y_pred\n",
    "\n",
    "    bins = [0, 4, 12, 18, 30, 50, 65, 100]  # This is somewhat arbitrary...\n",
    "    age_index = (1, 2, 3, 4, 5, 6, 7)\n",
    "    # ('baby','child','teenager','young','mid-age','over-50','senior')\n",
    "    df['Age-bin'] = pd.cut(df.Age, bins, labels=age_index).astype(int)\n",
    "\n",
    "    df['Ticket'] = df['Ticket'].replace(\n",
    "        ['A', 'W', 'F', 'L', '5', '6', '7', '8', '9'], '4')\n",
    "\n",
    "    df = df.drop(labels=['Cabin'], axis=1)\n",
    "\n",
    "    # fill the NAN\n",
    "    df.Embarked.fillna('S', inplace=True)\n",
    "\n",
    "    df = df.drop(labels='Embarked', axis=1)\n",
    "\n",
    "    # dummy encoding\n",
    "    df = pd.get_dummies(df, columns=['Ticket'])\n",
    "\n",
    "    df = df.drop(labels=['SibSp','Parch','Age','Fare','Title','PassengerId'], axis=1)\n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pi/anaconda3/envs/nitp-hack/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/home/pi/anaconda3/envs/nitp-hack/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "df = preprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'PassengerId'),\n",
       " (1, 'Survived'),\n",
       " (2, 'Pclass'),\n",
       " (3, 'Name'),\n",
       " (4, 'Sex'),\n",
       " (5, 'Age'),\n",
       " (6, 'SibSp'),\n",
       " (7, 'Parch'),\n",
       " (8, 'Ticket'),\n",
       " (9, 'Fare'),\n",
       " (10, 'Cabin'),\n",
       " (11, 'Embarked')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(pd.read_csv('train.csv').columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Survived'),\n",
       " (1, 'Pclass'),\n",
       " (2, 'Sex'),\n",
       " (3, 'Master'),\n",
       " (4, 'Miss'),\n",
       " (5, 'Mr'),\n",
       " (6, 'Mrs'),\n",
       " (7, 'Others'),\n",
       " (8, 'Family'),\n",
       " (9, 'Fare-bin'),\n",
       " (10, 'Age-bin'),\n",
       " (11, 'Ticket_1'),\n",
       " (12, 'Ticket_2'),\n",
       " (13, 'Ticket_3'),\n",
       " (14, 'Ticket_4'),\n",
       " (15, 'Ticket_C'),\n",
       " (16, 'Ticket_P'),\n",
       " (17, 'Ticket_S')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "list(enumerate(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Survived'),\n",
       " (1, 'Pclass'),\n",
       " (2, 'Sex'),\n",
       " (3, 'Master'),\n",
       " (4, 'Miss'),\n",
       " (5, 'Mr'),\n",
       " (6, 'Mrs'),\n",
       " (7, 'Others'),\n",
       " (8, 'Family'),\n",
       " (9, 'Fare-bin'),\n",
       " (10, 'Age-bin'),\n",
       " (11, 'Ticket_1'),\n",
       " (12, 'Ticket_2'),\n",
       " (13, 'Ticket_3'),\n",
       " (14, 'Ticket_4'),\n",
       " (15, 'Ticket_C'),\n",
       " (16, 'Ticket_P'),\n",
       " (17, 'Ticket_S')]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv('fullData_clean.csv', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('train.csv')\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3830c0ea-b163-4e51-b41a-212481e2684d",
    "_execution_state": "idle",
    "_uuid": "ad7631b36daae060b7159e668f30da96d28c8ff8"
   },
   "source": [
    "## Modeling and Prediction\n",
    "Now we can drop the features we don't need and split the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e859e686-72db-4608-a89e-24a9e9b52e47",
    "_execution_state": "idle",
    "_uuid": "df4d6e82a6a6fac2c995d55f829085f9afee3267"
   },
   "outputs": [],
   "source": [
    "\n",
    "y_train = df[0:891]['Survived'].values\n",
    "X_train = df[0:891].drop(['Survived','PassengerId'], axis=1).values\n",
    "X_test  = df[891:].drop(['Survived','PassengerId'], axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7d43fa72-d836-4641-b8e7-5d5e7102ba1f",
    "_execution_state": "idle",
    "_uuid": "9fd8449ddf8dbbc7ca0603d0c1fd1b65b272bb8d"
   },
   "source": [
    "(09/12/2017 update) Using NN gives better result than XGBoost and Random Forest do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1b0b8eed-36fc-4d4c-8ef1-1dc96becdc39",
    "_execution_state": "idle",
    "_kg_hide-output": true,
    "_uuid": "1dfd64f73918b8cacdb76f40a0a969c46accaefc"
   },
   "outputs": [],
   "source": [
    "# Initialising the NN\n",
    "def getModel():\n",
    "    model = Sequential()\n",
    "\n",
    "    # layers\n",
    "    model.add(Dense(units = 9, kernel_initializer = 'uniform', activation = 'relu', input_dim = 17))\n",
    "    model.add(Dense(units = 9, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    model.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "    # Compiling the ANN\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train the ANN\n",
    "model.fit(X_train, y_train, batch_size = 32, epochs = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ae0b0267-706b-4673-a5e1-5821edc2a9e4",
    "_execution_state": "idle",
    "_uuid": "8f65307ece4155513982147fc7bbc497074af201"
   },
   "source": [
    "We can now get the prediction. I got a public score of 0.81339 using the output from my laptop (python 2.7), which is different from what is generated here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4a651081-886a-4a9a-8324-a264483d0721",
    "_execution_state": "idle",
    "_uuid": "7a6c2f2885d7caf67993db99f6880d53e5880372"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_final = (y_pred > 0.5).astype(int).reshape(X_test.shape[0])\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': df_test['PassengerId'], 'Survived': y_final})\n",
    "output.to_csv('prediction-ann.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
